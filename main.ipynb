{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42afad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Imports and Configurations\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_PATH = \"yolov8n.pt\"\n",
    "TARGET_WIDTH = 640\n",
    "\n",
    "W_TRASH = 0.8\n",
    "W_FLOW = 0.2\n",
    "LOW_THR = 0.25\n",
    "HIGH_THR = 0.50\n",
    "MAX_FLOW_MAG = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def compute_trash_score(yolo_result, frame_shape):\n",
    "    h, w, _ = frame_shape\n",
    "    frame_area = float(w * h)\n",
    "    if frame_area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    total_box_area = 0.0\n",
    "    for box in yolo_result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        bw = max(0.0, float(x2 - x1))\n",
    "        bh = max(0.0, float(y2 - y1))\n",
    "        total_box_area += bw * bh\n",
    "\n",
    "    return float(np.clip(total_box_area / frame_area, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def compute_flow_mag(prev_gray, gray):\n",
    "    if prev_gray is None:\n",
    "        return 0.0\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prev_gray, gray, None,\n",
    "        pyr_scale=0.5, levels=3, winsize=15,\n",
    "        iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "    )\n",
    "\n",
    "    mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    return float(np.mean(mag))\n",
    "\n",
    "\n",
    "def normalize_flow(flow_mag, max_flow=MAX_FLOW_MAG):\n",
    "    return float(np.clip(flow_mag / max_flow, 0.0, 1.0))\n",
    "\n",
    "\n",
    "def risk_level(risk):\n",
    "    if risk < LOW_THR:\n",
    "        return \"LOW\", (0, 255, 0)\n",
    "    elif risk < HIGH_THR:\n",
    "        return \"MODERATE\", (0, 255, 255)\n",
    "    else:\n",
    "        return \"HIGH\", (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8bba0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "print(\"[INFO] Loading YOLOv8 model...\")\n",
    "model = YOLO(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e253b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Video Processing Function\n",
    "\n",
    "def process_video(video_path, model):\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    base = os.path.basename(video_path)\n",
    "    name, _ = os.path.splitext(base)\n",
    "    out_path = os.path.join(\"outputs\", f\"{name}_output.mp4\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Cannot open video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    src_fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "    src_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    src_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    target_w = TARGET_WIDTH\n",
    "    target_h = int(src_h * (target_w / src_w))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(out_path, fourcc, src_fps, (target_w, target_h))\n",
    "\n",
    "    print(f\"[INFO] Processing {video_path} ({src_w}x{src_h} -> {target_w}x{target_h})\")\n",
    "    print(f\"[INFO] Output will be saved to {out_path}\")\n",
    "\n",
    "    prev_gray = None\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        frame = cv2.resize(frame, (target_w, target_h))\n",
    "\n",
    "        # ---- YOLO INFERENCE (with FPS) ----\n",
    "        start_time = time.time()\n",
    "        results = model(frame, imgsz=640, conf=0.05, verbose=False)\n",
    "        inference_time = time.time() - start_time\n",
    "        fps = 1.0 / inference_time if inference_time > 0 else 0.0\n",
    "\n",
    "        r = results[0]\n",
    "\n",
    "        trash_score = compute_trash_score(r, frame.shape)\n",
    "        trash_pct = trash_score * 100.0\n",
    "\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow_mag = compute_flow_mag(prev_gray, gray)\n",
    "        prev_gray = gray\n",
    "\n",
    "        flow_norm = normalize_flow(flow_mag)\n",
    "\n",
    "        risk = W_TRASH * trash_score + W_FLOW * (1.0 - flow_norm)\n",
    "        level, color = risk_level(risk)\n",
    "\n",
    "        cv2.putText(frame, f\"TrashArea: {trash_pct:.2f}%\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"FlowMag: {flow_mag:.2f} (norm {flow_norm:.2f})\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Risk: {risk:.2f} [{level}]\", (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 120),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Frame {frame_idx}\", (10, target_h - 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"[DONE] Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952b6db",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "video_path = \"[]\"\n",
    "process_video(video_path, model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
